# ğŸ§ Accessible User Interface Design and Testing for People with Hearing Loss

An innovative solution that bridges the communication gap for people with hearing impairments using **Speech-to-ASL Conversion**, **Text-to-ASL Visualization**, and **3D Sign Language Modeling**. This system leverages **Python**, **Google Speech Recognition**, **Tkinter GUI**, **Unity**, and **Blender** to deliver a rich, accessible experience.

---

## ğŸ“Œ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Installation](#installation)
- [How to Run](#how-to-run)
- [Project Structure](#project-structure)
- [Screenshots](#screenshots)
- [Results & Usability](#results--usability)
- [Team Members](#team-members)
- [Future Enhancements](#future-enhancements)
- [License](#license)

---

## ğŸ§  Overview

This project was designed using the **User-Centered Design (UCD)** methodology following **ISO** and **Nielsen Norman Group (NNG)** standards. It helps users:
- Convert **text to ASL symbols**
- Translate **spoken language into ASL**
- Display **3D ASL hand signs** using Unity and Blender
- Conduct real-time speech-to-3D model translation

---

## âœ¨ Features

- ğŸ”  **Text to ASL Conversion** using image-based sign representation
- ğŸ™ï¸ **Speech to Text Recognition** via Googleâ€™s Speech API
- ğŸ¤– **Speech to ASL Converter** (text-to-image ASL transition)
- ğŸ§± **3D Modeling of ASL signs (0-9)** in Blender
- ğŸ•¹ï¸ **Unity-based 3D ASL Translator**
- ğŸ‘‚ **Voice-Activated ASL Display**

---

## ğŸ› ï¸ Technologies Used

- **Python 3**
- **Tkinter** (for GUI)
- **Google Speech Recognition API**
- **PIL / OpenCV** for image rendering
- **Blender** for 3D hand modeling
- **Unity** for real-time 3D interaction
- **Numpy**, **Pyaudio**, **SpeechRecognition**

---

## ğŸ’¾ Installation

1. Clone this repository:
```bash
git clone https://github.com/USERNAME/accessible-ui-hearing-loss.git
cd accessible-ui-hearing-loss
```

2. Install the required Python packages:
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run

### 1. **Text to ASL (Run in Python)**
```bash
python text_to_asl.py
```

### 2. **Speech to ASL (Run in Python)**
```bash
python speech_to_asl.py
```

### 3. **3D ASL Translator (Blender + Unity)**
- Open Blender files to view or modify 3D hand signs
- Use Unity to map recognized speech to Blender-based 3D models

---

## ğŸ—‚ï¸ Project Structure

```bash
Project/
â”‚
â”œâ”€â”€ asl_3d model translator.py       # Main translator script
â”œâ”€â”€ text_to_asl.py                   # Text to ASL GUI
â”œâ”€â”€ speech_to_asl.py                 # Speech to ASL translator
â”œâ”€â”€ speech_to_text.py                # Speech recognition standalone
â”œâ”€â”€ *.jpg / *.png                    # ASL image mappings
â”œâ”€â”€ hand0.png - hand9.png            # 3D hand sign images
â”œâ”€â”€ Blender Models/                  # 3D ASL symbols (0-9)
â”œâ”€â”€ Unity Project/                   # Unity-based interaction
â””â”€â”€ README.md                        # This file!
```

---

## âœ… Results & Usability

- ğŸ”Š **Speech Recognition Accuracy:** ~90%
- âœ‹ **Real-time ASL Feedback** on speech input
- ğŸ§© **High Satisfaction** from usability test participants
- ğŸ§˜â€â™‚ï¸ **Easy to Use** with minimal learning curve
- ğŸ¯ **ISO/NNG compliant** user interface

---

## ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Team Members

- **Sweta Patel** â€“ ğŸ“„ Documentation, Reporting
- **Vaishal Shah** â€“ ğŸ§± Blender 3D Modeling
- **Ujash Thakkar** â€“ ğŸ¤ Speech Recognition Integration
- **Dikshaben Patel** â€“ ğŸ•¹ï¸ Unity & Translator UI Testing
- **Nisha Raval** â€“ ğŸ” Research & 3D Modeling Support

---

## ğŸš€ Future Enhancements

- ğŸ§  Integrate **Machine Learning** for gesture prediction
- ğŸŒ Real-time web deployment
- ğŸ“š Add **ASL learning modules** (quizzes & lessons)
- ğŸ“± Build **mobile-friendly** versions

---

## ğŸ“œ License

This project is licensed under the **MIT License**. Feel free to use, modify, and enhance it with attribution.

